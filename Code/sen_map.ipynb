{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sen_map notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function \n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils\n",
    "import utils_DL\n",
    "import utils_s160159 as u_s\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './../Data'\n",
    "logs_path = './logs'\n",
    "BATCH_SIZE = 1 # 75\n",
    "NUM_SUBJECTS = 20\n",
    "NUM_CLASSES = 6\n",
    "#VAL_PER = 0.05\n",
    "#VAL_TRAIN_ID = NUM_SUBJECTS - int(NUM_SUBJECTS * VAL_PER) - 1\n",
    "VAL_TRAIN_ID = NUM_SUBJECTS - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load all subjects into memory\n",
    "subjects_list = []\n",
    "for i in range(VAL_TRAIN_ID+1, NUM_SUBJECTS+1):\n",
    "    print(\"Loading subject %d...\" %(i))\n",
    "    inputs_night1, targets_night1, _  = u_s.load_spectrograms(data_path=data_dir, \n",
    "                                                              subject_id=i, \n",
    "                                                              night_id=1)\n",
    "    if i!=20:\n",
    "        inputs_night2, targets_night2, _  = u_s.load_spectrograms(data_path=data_dir, \n",
    "                                                                  subject_id=i, \n",
    "                                                                  night_id=2)\n",
    "    else:\n",
    "        inputs_night2 = np.empty((0,224,224,3),dtype='uint8')\n",
    "        targets_night2 = np.empty((0,NUM_CLASSES),dtype='uint8')           \n",
    "\n",
    "    current_inputs = np.concatenate((inputs_night1,inputs_night2),axis=0)\n",
    "    current_targets = np.concatenate((targets_night1, targets_night2),axis=0)\n",
    "    \n",
    "    subjects_list.append([current_inputs, current_targets])\n",
    "        \n",
    "# extract image shapes\n",
    "IMAGE_SHAPE = subjects_list[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring the model and  create per class sensitivity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model_path = './models/basis/model.meta'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        # restore model\n",
    "        my_load = tf.train.import_meta_graph(model_path, clear_devices=True)\n",
    "        my_load.restore(sess, './models/basis/model')\n",
    "        grad_output_wrt_input = tf.get_collection('grad_output_wrt_input')[0]\n",
    "        x_pl = tf.get_collection('x_pl')[0]\n",
    "        y_pl = tf.get_collection('y_pl')[0]\n",
    "\n",
    "        #\n",
    "        for cur_class in range(NUM_CLASSES):\n",
    "            print('Creating sen_map of: ' + str(cur_class + 1) + ' of ' + str(NUM_CLASSES))\n",
    "            # Extract data\n",
    "            _data = [subjects_list[i] for i in range(len(subjects_list)) if np.argmax(subjects_list[i][1]) == cur_class]\n",
    "\n",
    "            inputs_data = np.empty((0,IMAGE_SHAPE[1],IMAGE_SHAPE[2],IMAGE_SHAPE[3]),dtype='uint8')  \n",
    "            targets_data = np.empty((0,NUM_CLASSES),dtype='uint8') \n",
    "\n",
    "            grad_accum = np.empty((0,IMAGE_SHAPE[1],IMAGE_SHAPE[2],IMAGE_SHAPE[3]))\n",
    "            x_batch_accum = np.empty((0,IMAGE_SHAPE[1],IMAGE_SHAPE[2],IMAGE_SHAPE[3]))\n",
    "\n",
    "            # loop data for current class\n",
    "            for item in _data:\n",
    "                inputs_data = np.concatenate((inputs_data, item[0]),axis=0)\n",
    "                targets_data = np.concatenate((targets_data, item[1]),axis=0)\n",
    "                # end loop\n",
    "\n",
    "            # loop mini bacthes\n",
    "            _iter = 0\n",
    "            for x_batch, y_batch in utils.iterate_minibatches(batchsize=BATCH_SIZE, \n",
    "                                                              inputs=inputs_data, \n",
    "                                                              targets=targets_data, \n",
    "                                                              shuffle=False):\n",
    "                _iter += 1\n",
    "                print(_iter, end='r')\n",
    "\n",
    "                # convert from uint8 to float32\n",
    "                #x_batch = np.float32(x_batch)/255.0\n",
    "\n",
    "                # feed trained network\n",
    "                _grads = sess.run(fetches=grad_output_wrt_input, \n",
    "                                  feed_dict={x_pl: x_batch,\n",
    "                                             y_pl: y_batch})\n",
    "\n",
    "                grad_accum = np.concatenate((grad_accum, _grads), axis=0) \n",
    "                x_batch_accum = np.concatenate((x_batch_accum, x_batch), axis=0) \n",
    "                break\n",
    "\n",
    "                # end loop\n",
    "\n",
    "            # Calcualte Sensitivity maps  \n",
    "            u_s.cal_sen_map(x_batch_accum, sen_map_class='raw_' + str(cur_class), \n",
    "                            save_dir = './pics/', IMAGE_SHAPE=IMAGE_SHAPE)\n",
    "            u_s.cal_sen_map(grad_accum, sen_map_class='loss_' + str(cur_class),\n",
    "                            save_dir = './pics/', IMAGE_SHAPE=IMAGE_SHAPE)\n",
    "\n",
    "        # close session\n",
    "        sess.close()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
