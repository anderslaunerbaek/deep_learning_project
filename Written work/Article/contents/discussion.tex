\section{Discussion}
\label{sec:discussion}



data targets have not been cross checked by the skill professionals..


how to encounter imblanced data classe:

-  random down sample in each epoch.. It can remove useful imformation
- use weigthingPenalized Models the the loss function
- learn the distribution of the miniorty classes and up sample those
his change is called sampling your dataset and there are two main methods that you can use to even-up the classes:



under sampling .. smide information væk... måske kan det give en bedre predectering???




You can add copies of instances from the under-represented class called over-sampling (or more formally sampling with replacement), or
You can delete instances from the over-represented class, called under-sampling.



i did not subtract the mean picture in traning... not normalize -> failure


batch normalization,


bat size... low -> fewer discarding images in the final batch



The CNN reducing spectral variance, this can be an issue for the LSTM...


Issues with the current approach--- video and spech are very different

Although using similar architecture, the type of input data we use and the ones in video prediction are quite different. Basically, if you compare one video frame with the next one, it is very likely that you have almost the same image with few changes (displacements) in it. In our case, though, two consecutive epochs can be quite different (in terms of the position of “objects”), and I guess that the approach proposed for video frames will not work. Notice that videos have 2 spatial dimension and 1 temporal. In our case, we have 1 spatial (frequency) and 1 temporal. If you want to use video frame like approach, it might be more useful to work with EEG scalp maps, when using multi-sensors, but that is a different problem.



We overfitting to one doctor openions.


BATCH norm should be used if there is trubles in the optimization.



Personal 
